{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_emotion_recognition_modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCgyun8W/L1//jE/Dt0CQF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shadfdz/speechEmotionRecognition/blob/master/Speech_emotion_recognition_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8df-NrCbtUe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6208555-e570-41b1-ce1f-39232fb4fefc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get emotion categories (remove calm it has been grouped with neutral prior)\n",
        "path = 'drive/MyDrive/processed_emotion_dataset/'\n",
        "sub_folder = glob.glob(path + '*')\n",
        "sub_folder.remove('drive/MyDrive/processed_emotion_dataset/calm')\n",
        "emotions = [i.split('/')[3] for i in sub_folder]\n",
        "emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SwSDrrZt56p",
        "outputId": "be33eec0-bf0e-4707-a9af-5db1d6eb5206"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print max and mean melspect shape for each file\n",
        "for cat in emotions:\n",
        "  f_list = glob.glob(path + cat + '/*')\n",
        "  print('Emotion category: \\'{}\\' Count: {}'.format(cat,len(f_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izTOkRB_yByp",
        "outputId": "af0baa7a-ce33-456d-996f-fcf2d3d56e7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion category: 'neutral' Count: 1619\n",
            "Emotion category: 'happy' Count: 1739\n",
            "Emotion category: 'sad' Count: 1739\n",
            "Emotion category: 'angry' Count: 1739\n",
            "Emotion category: 'fearful' Count: 1739\n",
            "Emotion category: 'disgust' Count: 1739\n",
            "Emotion category: 'surprised' Count: 469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_path = 'drive/MyDrive/processed_emotion_dataset/sad/'\n",
        "f_name = 'sad_0.wav'\n",
        "\n",
        "full = f_path + f_name\n",
        "# x, sr = librosa.load(f_path + f_name)\n",
        "# full.split('/')[1]\n",
        "full.split('/')[-1].split('_')[0]"
      ],
      "metadata": {
        "id": "rpKQYA0-uvHT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6463992-651a-478c-8077-3fab45dcf7d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Melspect Dataset Class"
      ],
      "metadata": {
        "id": "qmgTd0RHh4hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class audiodata(Dataset):\n",
        "  def __init__(self, file_paths, n_mels=128):\n",
        "    self.mels = n_mels\n",
        "    self.file_paths = file_paths\n",
        "    self.data = []\n",
        "    for f_name in file_paths:\n",
        "      emotion_category = f_name.split('/')[-1].split('_')[0]\n",
        "      self.data.append([f_name, emotion_category])\n",
        "    self.class_dict = {\"neutral\": 0,\n",
        "                    \"happy\": 1,\n",
        "                    \"sad\": 2,\n",
        "                    \"angry\": 3,\n",
        "                    \"fearful\": 4,\n",
        "                    \"disgust\": 5,\n",
        "                    \"surprised\": 6 \n",
        "                    }\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    audio_path, emotion_class = self.data[index]\n",
        "    x, sr = librosa.load(audio_path)\n",
        "    melspect = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=128, pad_mode='constant')\n",
        "    pad_crop_length = 128 - melspect.shape[1]\n",
        "    if pad_crop_length > 0:\n",
        "      melspect = np.pad(melspect, [(0,0),(0,pad_crop_length)], mode='constant')\n",
        "    if pad_crop_length < 0:\n",
        "      melspect = melspect[:,0:128]\n",
        "    # get emotion class code\n",
        "    class_code = self.class_dict[emotion_class]\n",
        "    audio_tensor = torch.from_numpy(melspect)\n",
        "    # audio_tensor = audio_tensor.permute(2, 0, 1)\n",
        "    return audio_tensor, class_code"
      ],
      "metadata": {
        "id": "bKTyhOOjh34H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Training, Validation, Test Split\n"
      ],
      "metadata": {
        "id": "zwwnUi2Hk1uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "LkzxyDkiB1UI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get paths for each emotion category\n",
        "sub_folder"
      ],
      "metadata": {
        "id": "U2WvD_Polacl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c1c473-bf0e-490a-c215-3b2b32fb4bfe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/processed_emotion_dataset/neutral',\n",
              " 'drive/MyDrive/processed_emotion_dataset/happy',\n",
              " 'drive/MyDrive/processed_emotion_dataset/sad',\n",
              " 'drive/MyDrive/processed_emotion_dataset/angry',\n",
              " 'drive/MyDrive/processed_emotion_dataset/fearful',\n",
              " 'drive/MyDrive/processed_emotion_dataset/disgust',\n",
              " 'drive/MyDrive/processed_emotion_dataset/surprised']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all files\n",
        "file_list = []\n",
        "for folder in sub_folder:\n",
        "  file_list += glob.glob(folder + \"/*\")"
      ],
      "metadata": {
        "id": "MkxgUHR7CiFK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "dataset = audiodata(file_list)"
      ],
      "metadata": {
        "id": "AWoBLdDXDMkC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_dataset(dataset, val_split=0.20):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets"
      ],
      "metadata": {
        "id": "e_iLvWr9DQAS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = train_val_dataset(dataset)\n",
        "print(len(datasets['train']))\n",
        "print(len(datasets['val']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8F6GQbZHDOs",
        "outputId": "211b6915-2549-4a72-e609-e699b90df157"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8626\n",
            "2157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {x:DataLoader(datasets[x],32, shuffle=True, num_workers=2) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMEX5jvHHETF",
        "outputId": "8ec688be-7c14-4da1-fb49-4a4e1527e1ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128, 128]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "ZjpB_7X4HZGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}