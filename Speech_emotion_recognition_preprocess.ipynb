{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech_emotion_recognition_preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeu7MD4clJqdievf1+OM0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shadfdz/speechEmotionRecognition/blob/master/Speech_emotion_recognition_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEoMLHJ0aPeO",
        "outputId": "81fd101b-b4ce-422f-aec5-90a83e6bd429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import re\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/speech_emotion_dataset/Crema"
      ],
      "metadata": {
        "id": "ebMH3d-AakdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders and group each emotion in the same folder\n",
        "\n",
        "os.chdir('drive/MyDrive')\n",
        "os.mkdir('processed_emotion_dataset')\n",
        "os.chdir('processed_emotion_dataset')\n",
        "\n",
        "emotion_cat = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
        "\n",
        "for cat in emotion_cat:\n",
        "  os.mkdir(cat)"
      ],
      "metadata": {
        "id": "l3i-4gpS_R5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show folder for each emotion\n",
        "os.chdir(os.path.dirname(os.getcwd()))\n",
        "!ls "
      ],
      "metadata": {
        "id": "473VqDIH__ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = 'drive/MyDrive/speech_emotion_dataset/'\n",
        "list_ds = glob.glob(dir_path + \"*\") "
      ],
      "metadata": {
        "id": "GbbNuSGmbXUp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Crema Dataset to Respective Emotion Folder"
      ],
      "metadata": {
        "id": "3quNtugYHUR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get crema file names\n",
        "crema_file_list = os.listdir(list_ds[1] + \"/\")"
      ],
      "metadata": {
        "id": "lsGP82eSCXl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get file paths of target\n",
        "emotion_folder_path_list = glob.glob('drive/MyDrive/processed_emotion_dataset/*')"
      ],
      "metadata": {
        "id": "YNZKPUrZFFJ-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary for emotion and file path\n",
        "emotion_folder_dict = {}\n",
        "for cat_path in emotion_folder_path_list:\n",
        "  emotion_folder_dict[cat_path.split('/')[3]] = cat_path"
      ],
      "metadata": {
        "id": "Y2Ud81rGDEUU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get crema file paths\n",
        "crema_paths = glob.glob(emotion_folder_path_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X8Z017HFuBI",
        "outputId": "679763fb-056e-4478-fe1b-17ff5afdf750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/speech_emotion_dataset/Savee',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Crema',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Ravdess']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get file paths\n",
        "crema_path_list = glob.glob(list_ds[1] + \"/*\")"
      ],
      "metadata": {
        "id": "suApPKPFGf-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary to map to emotion folder\n",
        "crema_emotions = {\n",
        "        \"SAD\": \"sad\",\n",
        "        \"ANG\": \"angry\",\n",
        "        \"DIS\": \"disgust\",\n",
        "        \"FEA\": \"fearful\",\n",
        "        \"HAP\": \"happy\",\n",
        "        \"NEU\": \"neutral\",\n",
        "}"
      ],
      "metadata": {
        "id": "EnOiZ0DiJHyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_folder_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yEe-jOtJOF1",
        "outputId": "a3e7db2e-8618-4946-b8c7-c625505008e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 'drive/MyDrive/processed_emotion_dataset/angry',\n",
              " 'calm': 'drive/MyDrive/processed_emotion_dataset/calm',\n",
              " 'disgust': 'drive/MyDrive/processed_emotion_dataset/disgust',\n",
              " 'fearful': 'drive/MyDrive/processed_emotion_dataset/fearful',\n",
              " 'happy': 'drive/MyDrive/processed_emotion_dataset/happy',\n",
              " 'neutral': 'drive/MyDrive/processed_emotion_dataset/neutral',\n",
              " 'sad': 'drive/MyDrive/processed_emotion_dataset/sad',\n",
              " 'surprised': 'drive/MyDrive/processed_emotion_dataset/surprised'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sort crema to appropriate emotion category\n",
        "for file in crema_path_list:\n",
        "  os.system('cp ' + file + ' ' + emotion_folder_dict.get(crema_emotions.get(file.split('_')[4])))"
      ],
      "metadata": {
        "id": "VDzftlogH4BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Savee Dataset to Respective Emotion Folder\n"
      ],
      "metadata": {
        "id": "rZhotFekSTIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary for savee emotions\n",
        "savee_emotions = {\n",
        "    \"a\": \"angry\",\n",
        "    \"d\": \"disgust\",\n",
        "    \"f\": \"fearful\",\n",
        "    \"h\": \"happy\",\n",
        "    \"n\": \"neutral\",\n",
        "    \"sa\": \"sad\",\n",
        "    \"su\": \"surprised\",\n",
        "}"
      ],
      "metadata": {
        "id": "9lAKpULbZHIz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get path of files in savee folder as list\n",
        "savee_path_list = glob.glob(list_ds[0] + \"/*\")"
      ],
      "metadata": {
        "id": "wfXzp736UfNN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy files to respective emotion\n",
        "for file in savee_path_list:\n",
        "  os.system('cp ' + file + ' ' + emotion_folder_dict.get(savee_emotions.get(re.sub(r'\\d+','',file.split('_')[3]).replace('.wav',''))))"
      ],
      "metadata": {
        "id": "ldVg-4WpY51S"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Ravdes Dataset to Respective Emotion Folder\n"
      ],
      "metadata": {
        "id": "hMKEFZi-a10F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create emotion dictionary to map to folder\n",
        "ravdess_emotions = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\",\n",
        "}"
      ],
      "metadata": {
        "id": "4jcd3M6jeFSx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_ds[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZySTxgwcZ0tG",
        "outputId": "ce26636a-9ce8-4907-c722-df9bdfe558f8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/speech_emotion_dataset/Ravdess'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list files\n",
        "!ls drive/MyDrive/speech_emotion_dataset/Ravdess/audio_speech_actors_01-24/Actor_01"
      ],
      "metadata": {
        "id": "9qlivS_5cdSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get file paths as list\n",
        "ravdes_path_list = glob.glob('drive/MyDrive/speech_emotion_dataset/Ravdess/audio_speech_actors_01-24/Actor_01' + '/*')"
      ],
      "metadata": {
        "id": "vD-k667uchSc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ravdes_path_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX8R3TKseTMj",
        "outputId": "f280e27e-5ad1-4020-b96c-01998d469265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move file to respective emotional folder\n",
        "for file in ravdes_path_list:\n",
        "  os.system('cp ' + file + ' ' + emotion_folder_dict.get(ravdess_emotions.get(file.split('-')[3])))\n",
        "  "
      ],
      "metadata": {
        "id": "qvlG048neiIv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Tess Dataset to Respective Emotion Folder\n"
      ],
      "metadata": {
        "id": "hnSxdXPjfsx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_ds[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OYvZU66bfGG-",
        "outputId": "b5f60f3b-ef60-42ed-f47e-54fad0160ebe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/MyDrive/speech_emotion_dataset/Tess'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list Tess folders\n",
        "!ls drive/MyDrive/speech_emotion_dataset/Tess/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS-qX1jrfeUa",
        "outputId": "2c214a50-e066-42a4-8a24-25c16bcc2f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OAF_angry    OAF_neutral\t    YAF_disgust  YAF_pleasant_surprised\n",
            "OAF_disgust  OAF_Pleasant_surprise  YAF_fear\t YAF_sad\n",
            "OAF_Fear     OAF_Sad\t\t    YAF_happy\n",
            "OAF_happy    YAF_angry\t\t    YAF_neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary map to emotion category\n",
        "tess_emotions = {\n",
        "    \"neutral\": \"neutral\",\n",
        "    \"happy\": \"happy\",\n",
        "    \"sad\": \"sad\",\n",
        "    \"angry\": \"angry\",\n",
        "    \"Fear\": \"fearful\",\n",
        "    \"disgust\": \"disgust\",\n",
        "    \"surprised\": \"surprised\",\n",
        "    \"surprise\": \"surprised\",\n",
        "    \"Sad\": \"sad\",\n",
        "    \"fear\": \"fearful\"\n",
        "}"
      ],
      "metadata": {
        "id": "hFxYs8DcfhuT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tess_folder_list = glob.glob('drive/MyDrive/speech_emotion_dataset/Tess' + '/*')\n",
        "tess_folder_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq1BbNUrigp9",
        "outputId": "cf31cda9-b085-4545-d9b5-3e9e39488063"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/speech_emotion_dataset/Tess/YAF_pleasant_surprised',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_happy',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_angry',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/YAF_happy',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/YAF_neutral',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/YAF_disgust',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_Fear',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/YAF_sad',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_Pleasant_surprise',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_disgust',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_neutral',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/OAF_Sad',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/YAF_fear',\n",
              " 'drive/MyDrive/speech_emotion_dataset/Tess/YAF_angry']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer files\n",
        "for subfolder in tess_folder_list:\n",
        "  os.system('cp -r ' + subfolder + '/. ' + emotion_folder_dict.get(tess_emotions.get(subfolder.split('_')[len(subfolder.split('_')) - 1])))"
      ],
      "metadata": {
        "id": "GAlb8OS_jthX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Distribution and Process Data"
      ],
      "metadata": {
        "id": "VYhtVmFGcsFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get emotion categories\n",
        "path = 'drive/MyDrive/processed_emotion_dataset/'\n",
        "sub_folder = glob.glob(path + '*')\n",
        "emotions = [i.split('/')[3] for i in sub_folder]\n",
        "emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG1NqrMTdLTk",
        "outputId": "492b4081-1c26-47c2-ff9a-fa79026fe0f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print count of each emotion category\n",
        "for cat in emotions:\n",
        "  f_list = glob.glob(path + cat + '/*')\n",
        "  print('Emotion category: \\'{}\\' Count: {}'.format(cat,len(f_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Bbw0q-dP3q",
        "outputId": "aff3e851-f0f7-4429-85ba-5ea162b33a6d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion category: 'neutral' Count: 1619\n",
            "Emotion category: 'happy' Count: 1739\n",
            "Emotion category: 'sad' Count: 1739\n",
            "Emotion category: 'angry' Count: 1739\n",
            "Emotion category: 'fearful' Count: 1739\n",
            "Emotion category: 'disgust' Count: 1739\n",
            "Emotion category: 'surprised' Count: 469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group calm and neutral\n",
        "source = sub_folder[1] + '/.'\n",
        "target = sub_folder[0] + '/.'\n",
        "os.system('cp -r ' + source + ' ' + target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9yPia2WfDUt",
        "outputId": "7c35fa9d-e3f6-42f6-b382-888a95f96bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove calm folder from list and count of each emotion category\n",
        "sub_folder.remove(sub_folder[1])\n",
        "emotions = [i.split('/')[3] for i in sub_folder]\n",
        "for cat in emotions:\n",
        "  f_list = glob.glob(path + cat + '/*')\n",
        "  print('Emotion category: \\'{}\\' Count: {}'.format(cat,len(f_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQlldrIZfXIb",
        "outputId": "94f8edcc-8529-4fed-883b-24bcfd6c39ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion category: 'neutral' Count: 1619\n",
            "Emotion category: 'happy' Count: 1739\n",
            "Emotion category: 'sad' Count: 1739\n",
            "Emotion category: 'angry' Count: 1739\n",
            "Emotion category: 'fearful' Count: 1739\n",
            "Emotion category: 'disgust' Count: 1739\n",
            "Emotion category: 'surprised' Count: 468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get max and min mel frequency array for padding\n",
        "ms_max = (0,0)\n",
        "for cat in sub_folder:\n",
        "  f_list = glob.glob(cat + '/*')\n",
        "  for file_name in f_list:\n",
        "    x, sr = librosa.load(file_name)\n",
        "    melspect = librosa.feature.melspectrogram(y=x, sr=sr)\n",
        "    if melspect.shape > ms_max:\n",
        "      ms_max = melspect.shape\n",
        "\n",
        "print(ms_max)"
      ],
      "metadata": {
        "id": "Az7Q-isTf0uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cat, sub_fold in zip(emotions, sub_folder):\n",
        "  folder = sub_fold + \"/\"\n",
        "  emotion_files = glob.glob(folder + \"*\")\n",
        "  num = 0\n",
        "  for f in emotion_files:\n",
        "    extension = f.split(\".\")[-1]\n",
        "    new_f_name = cat + \"_\" + str(num) + \".\" + extension\n",
        "    os.rename(f, folder + new_f_name)\n",
        "    num += 1\n",
        "  num = 0"
      ],
      "metadata": {
        "id": "7NWUipzj6gpN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, sr = librosa.load(sub_folder[6] + '/' + f_name)\n",
        "# stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
        "# print(stft.shape)\n",
        "# cqt = librosa.feature.chroma_cqt(y=x, sr=sr)\n",
        "# print(cqt.shape)\n",
        "n_mels = 128\n",
        "melspect = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=n_mels, pad_mode='constant')\n",
        "# pad_val = n_mels-melspect.shape[1]\n",
        "pad_val = 300\n",
        "melspect = np.pad(melspect, [(0,0),(0,pad_val)], mode='constant')\n",
        "print(melspect.shape)\n",
        "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
        "print(mfcc.shape)\n",
        "spec_roll = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
        "print(spec_roll.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOPmwnqZh0zK",
        "outputId": "d3247dc4-c893-4a22-933a-41db486f604f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 379)\n",
            "(20, 79)\n",
            "(1, 79)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melspect[:,0:128].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDAE7sqHjYEd",
        "outputId": "27a2f87b-5f36-4e2f-abc1-e84e292d4402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename each file\n"
      ],
      "metadata": {
        "id": "cl-JtTZXsWxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Custom Dataset"
      ],
      "metadata": {
        "id": "tDYM4LXOWZTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion category: 'neutral' Count: 1619\n",
        "Emotion category: 'happy' Count: 1739\n",
        "Emotion category: 'sad' Count: 1739\n",
        "Emotion category: 'angry' Count: 1739\n",
        "Emotion category: 'fearful' Count: 1739\n",
        "Emotion category: 'disgust' Count: 1739\n",
        "Emotion category: 'surprised' Count: 468"
      ],
      "metadata": {
        "id": "7TU2hAR8Xdt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32esO1pKXiRu",
        "outputId": "06e877da-0285-4771-efb5-7c1d8e3516ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/processed_emotion_dataset/neutral',\n",
              " 'drive/MyDrive/processed_emotion_dataset/happy',\n",
              " 'drive/MyDrive/processed_emotion_dataset/sad',\n",
              " 'drive/MyDrive/processed_emotion_dataset/angry',\n",
              " 'drive/MyDrive/processed_emotion_dataset/fearful',\n",
              " 'drive/MyDrive/processed_emotion_dataset/disgust',\n",
              " 'drive/MyDrive/processed_emotion_dataset/surprised']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class audiodata(Dataset):\n",
        "  def __init__(self, file_path, n_mels=128):\n",
        "    self.mels = n_mels\n",
        "    self.file_path = file_path\n",
        "    self.data = []\n",
        "    for sub_path in file_path:\n",
        "      emotion_category = sub_path.split(\"/\")[-1]\n",
        "      for audio_path in glob.glob(sub_path + \"/*\"):\n",
        "        self.data.append([audio_path, emotion_category])\n",
        "    self.class_dict = {\"neutral\": 0,\n",
        "                    \"happy\": 1,\n",
        "                    \"sad\": 2,\n",
        "                    \"angry\": 3,\n",
        "                    \"fearful\": 4,\n",
        "                    \"disgust\": 5,\n",
        "                    \"surprised\": 6 \n",
        "                    }\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    audio_path, emotion_class = self.data[index]\n",
        "    x, sr = librosa.load(audio_path)\n",
        "    melspect = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=128, pad_mode='constant')\n",
        "    pad_crop_length = 128 - melspect.shape[1]\n",
        "    if pad_crop_length > 0:\n",
        "      melspect = np.pad(melspect, [(0,0),(0,pad_crop_length)], mode='constant')\n",
        "    if pad_crop_length < 0:\n",
        "      melspect = melspect[:,0:128]\n",
        "    # get emotion class code\n",
        "    class_code = self.class_dict[emotion_class]\n",
        "    audio_tensor = torch.from_numpy(melspect)\n",
        "    # audio_tensor = audio_tensor.permute(2, 0, 1)\n",
        "    return audio_tensor, class_code"
      ],
      "metadata": {
        "id": "oGPW4Hvr_EAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}